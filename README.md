ğŸ¤– WhatsApp AI Analyzer

Uma ferramenta poderosa de RAG (Retrieval-Augmented Generation) local para anÃ¡lise profunda de conversas de WhatsApp. Transforme arquivos de texto em insights visuais e converse com seus dados usando IA, tudo rodando localmente para garantir privacidade total.

âœ¨ Funcionalidades

ğŸ•µï¸ IngestÃ£o Inteligente: Processa arquivos _chat.txt exportados do WhatsApp (Android/iOS), limpando logs de sistema e formatando dados.

ğŸ§  RAG Local & Privado: Usa Qdrant para vetorizaÃ§Ã£o semÃ¢ntica e DeepSeek R1 (via Ollama) para raciocÃ­nio complexo sobre as conversas.

ğŸ“Š Dashboard Interativo:

Timeline de Sentimento: Analisa o humor do grupo ao longo do tempo.

Rede de InteraÃ§Ãµes: Grafo visual mostrando quem responde a quem.

Nuvem de Palavras: Termos mais utilizados.

Monitoramento de Hardware: Acompanhe o uso de CPU, RAM e GPU (Suporte a AMD ROCm) em tempo real.

âš¡ Otimizado para GPU: Configurado para rodar eficientemente em GPUs com 8GB VRAM (Testado em AMD Radeon RX 6600 XT).

ğŸ› ï¸ PrÃ©-requisitos

Antes de comeÃ§ar, certifique-se de ter instalado:

Python 3.10+

Ollama (Para rodar o modelo de IA).

Drivers de GPU (Recomendado para performance, mas funciona em CPU).

Linux (AMD): Drivers ROCm instalados.

Windows/Linux (NVIDIA): Drivers CUDA.

ğŸš€ InstalaÃ§Ã£o

Clone o repositÃ³rio:

git clone [https://github.com/fastphoenixx/whatsapp-ai-analyzer.git](https://github.com/fastphoenixx/whatsapp-ai-analyzer.git)
cd whatsapp-ai-analyzer


Crie e ative um ambiente virtual:

python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows


Instale as dependÃªncias:

pip install -r requirements.txt


> Nota para usuÃ¡rios AMD: Certifique-se de instalar a versÃ£o do PyTorch compatÃ­vel com ROCm se quiser aceleraÃ§Ã£o de GPU.

Baixe o modelo no Ollama:

ollama pull deepseek-r1:8b


ğŸ® Como Usar

1. Inicie o Servidor Ollama

Abra um terminal separado para rodar o backend da IA.

Para usuÃ¡rios AMD (Linux/ROCm):

OLLAMA_FLASH_ATTENTION=0 HSA_OVERRIDE_GFX_VERSION=10.3.0 ollama serve


Para usuÃ¡rios NVIDIA ou CPU:

ollama serve


2. Inicie o Dashboard

No terminal do projeto (com o venv ativo):

streamlit run src/interface/app.py


3. Acesse e Analise

O navegador abrirÃ¡ automaticamente em http://localhost:8501.

Na barra lateral, faÃ§a o upload do seu arquivo exportado do WhatsApp (_chat.txt).

No WhatsApp: Abra a conversa -> TrÃªs pontinhos -> Mais -> Exportar conversa -> Sem MÃ­dia.

Clique em "Iniciar AnÃ¡lise" e acompanhe o progresso no terminal embutido.

ğŸ“‚ Estrutura do Projeto

whatsapp-ai-analyzer/
â”œâ”€â”€ data/                  # Armazenamento local (ignorado pelo Git)
â”‚   â”œâ”€â”€ raw/               # Chats brutos
â”‚   â”œâ”€â”€ processed/         # Parquet estruturado
â”‚   â””â”€â”€ qdrant_db/         # Banco vetorial
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/         # Parsers e limpeza de texto
â”‚   â”œâ”€â”€ embeddings/        # GeraÃ§Ã£o de vetores e Qdrant
â”‚   â”œâ”€â”€ analysis/          # Scripts de Sentimento, Grafos e Trends
â”‚   â”œâ”€â”€ llm/               # IntegraÃ§Ã£o com Ollama
â”‚   â””â”€â”€ interface/         # Frontend Streamlit
â”œâ”€â”€ requirements.txt       # DependÃªncias do projeto
â””â”€â”€ README.md              # Este arquivo


ğŸ›¡ï¸ Privacidade

Este projeto foi desenhado para ser 100% Local.

Nenhum dado das suas conversas sai da sua mÃ¡quina.

Nenhum dado Ã© enviado para APIs de terceiros (como OpenAI ou Google).

Tudo Ã© processado na sua RAM/GPU e armazenado na pasta data/ localmente.

ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir Issues ou Pull Requests para melhorar a anÃ¡lise de sentimentos, adicionar novos grÃ¡ficos ou suportar novos modelos.

Desenvolvido com â¤ï¸ e muita cafeÃ­na.
